{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSDKUfxRg6FiKK4stP2RZP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sankalpa0011/Chatbot-Using-LangChain-and-OpenAI/blob/main/Chatbot_Using_LangChain_and_OpenAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7m0SHwlNFQS",
        "outputId": "c04d57e8-e949-4b74-d2e7-37de5d21e8c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m590.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.3/990.3 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.2/374.2 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.0/337.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install the necessary package\n",
        "!pip install langchain -qU\n",
        "!pip install langchain-openai -qU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "from google.colab import userdata # for use of secrete key"
      ],
      "metadata": {
        "id": "2Ns5ezvbON9Z"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Initialize OpenAI LLM**"
      ],
      "metadata": {
        "id": "pobqbqqDOYsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Set OpenAI API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Initialize the ChatOpenAI model\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    temperature=0\n",
        ")"
      ],
      "metadata": {
        "id": "S9-kDDz4ON2w"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Initialize Prompt Template**"
      ],
      "metadata": {
        "id": "0nbC3NrRwK5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Create a prompt template\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are an intelligent chatbot. Answer the following question.\"),\n",
        "    (\"user\", \"{question}\")\n",
        "])"
      ],
      "metadata": {
        "id": "rHc0Ad_IwPca"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Initialize Output Parser**"
      ],
      "metadata": {
        "id": "zmdy4mpXwl98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "p1RDjXLXwqjt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Chain The Prompt, LLM, And Output Parser**"
      ],
      "metadata": {
        "id": "yq00nVRJw0Zc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | llm | parser"
      ],
      "metadata": {
        "id": "i4s3EJtOwzs_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"My name is Sankalpa\"\n",
        "\n",
        "response = chain.invoke({\"question\": question})\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9Lj_QONxCES",
        "outputId": "fbb604be-ca16-43e1-a088-1306efcf8b9f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, Sankalpa! How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Initialize Prompt Template For Dynamic Interacion**"
      ],
      "metadata": {
        "id": "LeI5FOIpxpSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import MessagesPlaceholder\n",
        "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    SystemMessage(content=\"You are an intelligent chatbot. Answer the following question.\"),\n",
        "    MessagesPlaceholder(variable_name=\"question\"),\n",
        "])"
      ],
      "metadata": {
        "id": "KWOSfgVKxwvs"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Chain The Prompt, LLM, And Output Parser**"
      ],
      "metadata": {
        "id": "EC8HEJ1iyY7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | llm | parser"
      ],
      "metadata": {
        "id": "xFualk1eyYTI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"My name is Sankalpa\"\n",
        "\n",
        "response = chain.invoke({\"question\": [HumanMessage(content=question)]})\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhwJjMuFykjX",
        "outputId": "094482c7-7aad-415b-840c-7e83c2509a6c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, Sankalpa! How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Who am I?\"\n",
        "\n",
        "response = chain.invoke({\"question\": [HumanMessage(content=question)]})\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeX022Lly3eY",
        "outputId": "cedc6f14-204c-406d-fa2b-5de85107fcc2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm sorry, but as an AI chatbot, I don't have personal information about you. How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Initialize Prompt Template With Predefined Conversation History**"
      ],
      "metadata": {
        "id": "IznnKHQgy_aT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a prompt template with a predefined conversation history and a new question placeholder\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        SystemMessage(content=\"You are an intelligent chatbot. Answer the following question.\"),\n",
        "        HumanMessage(content=\"My name is Sankalpa\"),\n",
        "        AIMessage(content=\"Nice to meet you Sankalpa!. How can I assist you today?\"),\n",
        "        MessagesPlaceholder(variable_name=\"question\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "vFdPr7uvzyYG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | llm | parser"
      ],
      "metadata": {
        "id": "OfKRYtfp0rSG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Who am I?\"\n",
        "\n",
        "response = chain.invoke({\"question\": [HumanMessage(content=question)]})\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixJ9REIF0xlH",
        "outputId": "3fab81eb-f72e-444c-9bca-1d9a183d36ec"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are Sankalpa, a unique individual with your own thoughts, feelings, and experiences.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Initialize Prompt Template To Handle Dynamic Conversation History**"
      ],
      "metadata": {
        "id": "He04dVee06DD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        SystemMessage(content=\"You are an intelligent chatbot. Answer the following question.\"),\n",
        "        MessagesPlaceholder(variable_name=\"history\"),\n",
        "        MessagesPlaceholder(variable_name=\"question\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "4PPEhwmQ1DNT"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the conversation history\n",
        "history = [\n",
        "    HumanMessage(content=\"My name is Sankalpa\"),\n",
        "    AIMessage(content=\"Nice to meet you Sankalpa!. How can I assist you today?\"),\n",
        "    HumanMessage(content=\"What is 2*2\"),\n",
        "    AIMessage(content=\"4\"),\n",
        "]"
      ],
      "metadata": {
        "id": "Xt3z_QwS1TmP"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | llm | parser"
      ],
      "metadata": {
        "id": "iNI4VQrI1j3p"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Who am I?\"\n",
        "\n",
        "response = chain.invoke({\"history\": history, \"question\": [HumanMessage(content=question)]})\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tohxaTlC1pxP",
        "outputId": "71e95729-5ff7-450e-c653-f165f10f6115"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are Sankalpa.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Update And Display Conversation History**"
      ],
      "metadata": {
        "id": "-BMwUve_13bf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sg3EuKY11410",
        "outputId": "80db3741-e146-4a11-9437-d924bb394e9d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='My name is Sankalpa'),\n",
              " AIMessage(content='Nice to meet you Sankalpa!. How can I assist you today?'),\n",
              " HumanMessage(content='What is 2*2'),\n",
              " AIMessage(content='4')]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Extend The History With The Latest Question And Response**"
      ],
      "metadata": {
        "id": "UtJOWW4612b-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history.extend([HumanMessage(content=question), AIMessage(content=response)])"
      ],
      "metadata": {
        "id": "9ekq4gSr2Sjf"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nk4SmVwy2lIA",
        "outputId": "98375c8d-bd04-40e8-96fb-090bcfb829c8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='My name is Sankalpa'),\n",
              " AIMessage(content='Nice to meet you Sankalpa!. How can I assist you today?'),\n",
              " HumanMessage(content='What is 2*2'),\n",
              " AIMessage(content='4'),\n",
              " HumanMessage(content='Who am I?'),\n",
              " AIMessage(content='You are Sankalpa.')]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is my last question\"\n",
        "\n",
        "response = chain.invoke({\"history\": history, \"question\": [HumanMessage(content=question)]})\n",
        "\n",
        "history.extend([HumanMessage(content=question), AIMessage(content=response)])\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TimCLR-U2p18",
        "outputId": "cfe7bcb5-a99a-4540-d21f-23010ee79f0f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your last question was \"Who am I?\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnSj9-363LOW",
        "outputId": "2066f7d7-1470-4633-e42c-844122e03a0b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='My name is Sankalpa'),\n",
              " AIMessage(content='Nice to meet you Sankalpa!. How can I assist you today?'),\n",
              " HumanMessage(content='What is 2*2'),\n",
              " AIMessage(content='4'),\n",
              " HumanMessage(content='Who am I?'),\n",
              " AIMessage(content='You are Sankalpa.'),\n",
              " HumanMessage(content='What is my last question'),\n",
              " AIMessage(content='Your last question was \"Who am I?\"')]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the last four interaction in the conversation history\n",
        "history[-4:]  # restrict the lenth of the history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26E-AgBM3OJv",
        "outputId": "003a0e5b-f760-4693-8ad5-2eb53f138509"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='Who am I?'),\n",
              " AIMessage(content='You are Sankalpa.'),\n",
              " HumanMessage(content='What is my last question'),\n",
              " AIMessage(content='Your last question was \"Who am I?\"')]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}